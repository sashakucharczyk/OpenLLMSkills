# Sentiment Analysis Skill ‚Äî Instructions

This skill reads a CSV file and assigns a sentiment score and reasoning to each row based on a specified text column.

## Purpose
To classify natural-language text into sentiment categories defined by the user, using contextual, human-like interpretation rather than rule-based or keyword-based logic.

## What This Skill Does
- Reads each row from a CSV.
- Interprets the text in a specified input column.
- Assigns exactly one sentiment label per row.
- Writes a new CSV with:
  - the original columns (unchanged)
  - a sentiment label column
  - a reasoning column

## What You (the LLM) Must Do
When annotating rows:
1. Read the text as natural language.
2. Infer sentiment using contextual understanding.
3. Write:
   - A sentiment label from the user-defined scale.
   - A short reasoning (1‚Äì2 sentences) grounded in the row‚Äôs text.

## Hard constraints

**You ARE allowed to write and run simple Python code** to:
- Read the input CSV
- Iterate over rows (optionally in chunks)
- Build the output rows
- Write the final output CSV

The **sentiment decision itself** must come from natural-language understanding, not from:
- Explicit sentiment lexicons (lists of ‚Äúpositive/negative words‚Äù etc.)
- Numeric scoring schemes (e.g., accumulating a `score` and mapping score ranges)
- Rule-based token/regex patterns as the *primary* decision mechanism

You MUST NOT:
- Create new standalone source code files (no extra `.py`/`.js` checked into the repo)
- Import or call external sentiment-analysis libraries or models (TextBlob, VADER, transformers, etc.)
- Design a custom scoring engine whose main purpose is to compute sentiment 

### üåø **Required Behavior**
- Sentiment must be based on *meaning*, not word presence.
- Reasoning must be *row-specific*, not templated.
- Output must preserve:
  - row order
  - original columns
  - CSV formatting integrity

## Scale and chunking

- If a dataset is too large to run in a single attempt, chunking it is permitted.
- Process rows in batches (e.g., 300 at a time) in a loop.
- Append each processed batch to an in-memory list or write incrementally.
- Ensure every row in the input appears exactly once in the output.
- Preserve row order from the original CSV.

Chunking is an internal implementation detail. The user still expects **one final output CSV** with all rows annotated.

## Output Format Requirements
The final CSV must append two new columns:

1. `Sentiment`
2. `Reasoning`

Each row must have exactly one sentiment label.

## Notes
- The sentiment labels (e.g., 1‚Äì5, or custom strings) will be specified by the user at runtime.
- All file paths and driver-level instructions are defined in `sentiment_driver.py`.